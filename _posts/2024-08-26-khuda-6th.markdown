---
layout: post
title: 	"5th-week ML"
date: 	2024-08-26 15:52:17 +0900
categories: KhuDa
---

# 06. 비지도 학습

# 06-1. 군집알고리즘
## 비지도 학습이란?

타깃을 모르는 비지도 학습


타깃이 없을 때 사용하는 머신러닝 알고리즘이 있다. 

이를 비지도 학습(unsupervised learning)이라고 한다.


## 비지도 학습 해보기

### 사진 데이터 준비하기
준비한 사진은 **흑백**

이 사진 데이터는 넘파이 배열의 기본 저장 포맷인 **npy 파일**로 저장

colab에서 아래 명령어로 실행 가능

!wget https://bit.ly/fruits_300 -O fruits_300.npy

용어 설명 

! : colab에서 이후의 명령을 파이썬 코드가 아닌 **리눅스 셸(shell)** 명령으로 이해함.

wget : 원격 주소에서 데이터를 다운로드하여 저장하는 기능

-O : 저장할 파일 이름을 지정할 수 있다.

이를 통해 file <fruits_300.npy> 가 만들어진다.

```python
#데이터 로드
import numpy as np
import matplotlib.pyplot as plt

fruits = np.load('fruits_300.npy')

#fruits의 크기
print(fruits.shape)
#(300, 100, 100)
# 1st dim. 300 : 샘플의 개수
# 2nd dim. 100 : 이미지 높이
# 3rd dim. 100 : 이미지 너비

# 첫번째 이미지의 첫번째 행을 출력하고자 할 때
print(fruits[0,0,:])
#이는 (1,100)의 크기인 넘파이 행렬이 완성한다.
```

그럼 이를 이미지로 어떻게 바꿈??

맷플롭립의 imshow() 함수를 사용하면 넘파이 배열로 이미지를 쉽게 그릴 수 있다.

흑백이므로 cmap 매개변수를 'gray'로 지정한다.

```python
plt.imshow(fruits[0],cmap='gray')
plt.show()
```

보통의 사진은 물체가 짙고, 배경이 밝다.

- 하지만 이 사진에선 물제가 밝은 이유는 넘파이 배열로 변환할 때 반전시킨 것이다. 
    - 우리의 관심은 사과이기 때문이다.
    - 컴퓨터가 255에 집중하는 의미는 곱과 덧셈이 가능하기 때문이다.

반전을 하고 싶다면 cmap에서 'gray_r'을 해보자.
```python
fig, axs = plt.subplots(1,2)
axs[0].imshow(fruits[100],cmap='gray_r')
axs[1].imshow(fruits[200],cmap='gray_r')
plt.show()
```

- subplots() : 여러개의 그래프를 배열처럼 쌓을 수 있다.
    - 이 함수의 2개의 매개변수는 쌓을 행과 열을 지정합니다. 여기에서는 하나의 행과 2개의 열을 지정한다.
- axs는 2개의 서브 그래프를 담고 있는 배열이다.

### 사진 데이터 분석하기
사진은 사과, 파인애플, 바나나로 구성되어 있다.

각 사진의 평균을 내서 차이를 확인해보자.

1) 이미지 변환
    이미지를 변환하여 100x100을 펼쳐 10,000인 1차원 배열로 만든다.

    how?
    ```python
    #1. slicing
    #2. reshape를 통한 100*100을 10,000으로
    apple = fruit[0:100].reshape(-1,100*100)
    pineapple = fruits[100:200].reshape(-1,100*100)
    banana = fruits[200:300].reshape(-1,100*100)
    print(apple.shape)
    #(100,10000)
    #np.mean()
    print(apple.mean(axis=1))
    # 크기가 100인 배열이 나온다.
    ```
![alt text](image-56.png)

- 이렇게 구한 픽셀 평균값을 히스토그램을 통해 분포를 알 수 있다.
    - 히스토그램: 발생한 빈도를 그래프로 표시한 것. x축은 값의 구간, y축은 발생 빈도
```python
plt.hist(np.mean(apple,axis=1),alpha=0.8)
plt.hist(np.mean(pineapple,axis=1),alpha=0.8)
plt.hist(np.mean(banana,axis=1),alpha=0.8)
#alpha는 1보다 작게 하여 투명도를 만든다.

plt.legend(['apple','pineapple','banana'])
plt.show()
```
1) hist(np.mean(),alpha)

2) plt.legend : 어떤 과일의 히스토그램인지 범례를 만들어 본다.

3) np.mean() : 평균을 구한다.

![alt text](image-57.png)

#### 다음 분석 방법
픽셀의 평균값이 아닌 픽셀별 평균값을 찾아보자.
```python
#픽셀 10,000개에 대한 평균값을 막대 그래프로 그려 보겠습니다.
fig, axs = plt.subplots(1,3,figsize=(20,5))
axs[0].bar(range(10000), np.mean(apple,axis=0))
axs[1].bar(range(10000), np.mean(pineapple, axis=0))
axs[2].bar(range(10000), np.mean(pineapple, axis=0))
plt.show()
```
![alt text](image-59.png)

이 사진은 각 10,000개의 픽셀을 각각 평균하여 그래프로 해놓은 것이다.

사과는 아래로 갈수록 값이 높아지고, 파인은 비교적 고르고, 바나나는 중앙의 픽셀이 높다.

위는 수치상으로 비교한 것이고, 아래는 이미지로 출력한 것이다.

```python
apple_mean = np.mean(apple, axis=0).reshape(100,100)
pineapple_mean = np.mean(pineapple, axis=0).reshape(100,100)
banana_mean = np.mean(banana,axis=0).reshape(100,100)
fig, axs = plt.subplots(1,3,figsize=(20,5))
axs[0].imshow(apple_mean, cmap='gray_r')
axs[1].imshow(pineapple_mean, cmap='gray_r')
axs[2].imshow(banana_mean, cmap='gray_r')
plt.show()
```

이런 이미지에 가까운 이미지를 골라낸다면 구분할 수 있지 않을까?

#### 평균값에 가까운 사진 고르기
방법은 샘플의 값에 평균값을 뺀 절댓값 오차를 사용해보자.

1) 절댓값 구하기

이용함수 : abs() 함수를 이용한다.

np.abs(-1) >> return 1

np.abs() == np.absolute()
```python
abs_diff = np.abs(fruits-apple_mean)
abs_mean = np.mean(abs_diff, axis=(1,2))
# _diff는 (300,100,100) 크기의 배열인데, 각 샘플에 대한 평균을 구하기
# 위해 axis에서 2번째, 세번째 차원을 모두 지정했다.
```
2) 차이값 sort하기

apple_mean과 오차가 가장 작은 샘플 100개를 고르는 셈이다.

np.argsort() 함수는 작은 것에서 큰 순서대로 나열한 abs_mean 배열의 인덱스를 반환한다.

```python
apple_index = np.argsort(abs_mean)[:100]
fig, axs = plt.subplots(10,10,figsize =(10,10))
for i in range(10):
    for j in range(10):
        axs[i,j].imshow(fruits[apple_index[i*10 +j]], cmap='gray_r')
        axs[i,j].axis('off')
plt.show()
# 평균에 가까운 100개의 사진을 가져왔다.
# off는 좌표축을 그리지 않는다.
```

이렇게 비슷한 샘플끼리 그룹으로 모으는 작업을 군집(clustering)이라고 한다. 

군집 알고리즘으로 만든 그룹을 클러스터(cluster)라고 한다.

근데 답도 없는 상황에서 어떻게 할 수 있는 거??

# 06-2 k-평균
위는 답을 알수 있었다. 그런데 답을 모르는 경우는 어떻게 해야 하니?

이런 경우는 k-means clustering algorithm으로 평균값을 찾는다.

이 평균값은 클러스터의 중심에 위치하므로 클러스터 중심 또는 센트로이드라고 한다.

k-means clustering algorithm

cluster center

centroid


## k-means clustering algorithm 이란?
작동 방식
1) 무작위 k개의 클러스터 중심을 정한다.
2) 각 샘플에서 가장 가까운 클러스터 중심을 찾아 해당 클러스터의 샘플로 지정한다.
3) 클러스터에 속한 샘플의 평균값으로 **클러스터 중심**을 변경
4) 클러스터 중심에 변화가 없을때까지 2번으로 돌아가 반복


- 랜덤하게 중심을 지정한다. 
- 중심에서 가장 가까운 샘플들을 하나의 클러스터
- 거기서 대부분의 클래스가 있는 샘플로 쪽으로 점을 이동시킨다.

## KMeans class 사용
!wget http://bit.ly/fruits_300 -O fruits_300.npy

npy를 읽어 넘파일 배열을 준비한다.
```python
import numpy as np
fruits = np.load('fruits_300.npy')
fruits_2d = fruits.reshape(-1,100*100)
```

모델 가져오기
```python
from sklearn.cluster import KMeans
km = KMeans(n_clusters=3, random_state=42)
km.fit(fruits_2d)
```

클러스터의 군집 결과는 labels_ 속성에 저장된다. 이 길이는 샘플 개수로 각 샘플이 어떤 레이블에 해당하는지 나타낸다. n_clusters=3으로 지정했기에 labels_ 배열의 값은 0,1,2중 하나이다.

```python
print(km.labels_)

print(np.unique(km.labels_, return_counts= True))
# array([0,1,2], dtype=int32), array([91,98,111])
# 레이블 0에는 91개 1에는 98개, 2에는 111개의 샘플이 모았다.
```

그림을 출력하는 함수
```python
import matplotlib as plt
def draw_fruits(arr, ratio=1):
    n=len(arr) # n = 샘플의 개수이다.
    # 한 줄에 10개씩 이미지를 그린다. 샘플 개수를 10으로 나누어 전체 행 개수를 계산한다.
    rows = int(np.ceil(n/10))
    # 행이 1개이면 열의 개수는 샘플 개수입니다. 그렇지 않으면 10개이다.
    cols = n if rows<2 else 10
    fig, axs = plt.subplots(rows, cols, figsize=(cols*ratio, rows*ratio), squeeze= False)
    for i in range(rows):
        for j in range(cols):
            if i*10 +j<n:
                axs[i,j].imshow(arr[i*10+j], cmap='gray_r')
            axs[i,j].axis('off')
    plt.show()
# 이 함수는 (샘플 개수, 너비, 높이)의 3차원 배열을 입력받아.
# 가로로 10개씩 이미지를 출력한다.
# 샘플 개수에 따라 행과 열의 개수를 계산하고 figsize를 지정합니다. ratio에 비례하여 커진다.
# 2중 for문으로 첫번째 행을 따라 이미지를 그린다. 그리고 두번째 행의 이미지를 그리는 식으로 진행한다.

```
호출하는 방법 

불리언 인덱싱을 이용한다.

```python
draw_fruits(fruits[km.labels_==0])
```
이에 대해 종종 오류가 나오는 모습을 보여주었지만 다들 좋은 결과를 도출해냈다.

## 클러스터 중심
KMeans 클래스에서 최종적으로 찾은 클러스터 중심은 **cluster_centers_** 속성에 저장되어 있다. 이 배열은 fruits_2d 샘플의 클러스터 중심이기 때문에 이미지로 출력하려면 100X100 크기의 2차원 배열로 바꿔야 한다.

```python
draw_fruits(km.cluster_centers_.reshape(-1,100,100),ratio=3)
```

KMeans 클래스에는 훈련 데이터 샘플에서 클러스터 중심까지 거리로 변환해주는 transfrom() 메서드를 가지고 있다. transform()메서드가 있다는 것은 마치 StandardScaler 클래스처럼 특성값을 변환하는 도구로 사용할 수 있다는 의미이다. 

- 주의 : 인덱스가 100인 샘플에 transform() 메서드를 적용해 보죠. fit() 메서드와 마찬가지로 2차원 배열을 기대합니다. 
    - fruits_2d[100]처럼 사용하면 에러가 발생한다. 슬라이싱 연산자를 사용해서 (1,10000) 크기의 배열을 전달해야 한다.
```python
print(km.trasform(fruites_2d[100:101]))
# [[5267 8837 3393]]
# 각각 0, 1, 2로 표현된다.
print(km.predict(fruites_2d[100:101]))
# 가장 가까운 [2]를 예측한다.
```
```python
draw_fruits(fruits[100:101])
# 파인애플 사진
```
```python
print(km.n_iter_)
# 3
```

## 최적의 k 찾기
k를 찾기 위해 몇가지 도구가 있다.

여기선 **엘보우** 방법을 살펴볼 것이다.

- inertia(이너셔) : 거리의 제곱의 합
    - 클래스의 개수가 늘어나면 클러스터 개객의 크기는 줄어들기 때문에 이너셔도 줄어든다.

최적의 k를 찾는 방법
```python
inertia = []
for k in range(2,7):
    km = KMeans(n_clusters = k, random_state=42)
    km.fit(fruits_2d)
    inertia.append(km.inertia_)
plt.plot(range(2,7),inertia)
plt.show()
```
![alt text](image-60.png)

# 06-3 주성분 분석
## intro
k-평균 알고리즘으로 업로드된 사진을 클러스터로 분류하여 폴더별로 저장했다. 

그래서 계속 업로드하는 방향으로 진행했다.

여기서 발생한 문제는 저장공간이 부족했다.

어떻게 하면 사진의 용량을 줄일 수 있을까?

## 차원과 차원 축소
이전의 우리는 데이터가 가진 속성을 **특성**이라 불렀다.

과일 사진의 경우 10,000개의 픽셀이 있기에, 이는 10,000개의 특성이 있는 셈이다.

머신러닝에서는 이런 특성을 **차원(dimension)**이라고 한다.
![alt text](image-61.png)

- **차원 축소 알고리즘이란?**
    - 3장에선 특성이 많아지면, 성능과 함께 과적합이 된다.
    - 차원축소는 데이터를 가장 잘 나타내는 일부 특성을 선택하여 데이터 크기를 줄이고, 지도 학습 모델의 성능을 향상시킬 수 있는 방법
    - 이는 다시 복원도 가능하다.
        - 예시 : 주성분 분석(PCA)
## 주성분 분석 소개
주성분이란? 

데이터의 분산을 가장 잘 표현할 수 있는 벡터를 이르는 말이다.

주성분의 벡터의 원소 개수 == 원본 데이터셋에 있는 특성 개수

주성분으로 바꾼 데이터는 차원이 줄어든다.

다음 주성분의 방향은 기존의 주성분과 수직이면서 분산이 가장 큰 방향이다.

### PCA 클래스

1) 데이터 가져오기
!wget http://bit.ly/fruits_300 -O fruits_300.npy
```python
import numpy as np
fruits = np.load('fruits_300.npy')
fruits_2d = fruits.reshape(-1,100*100)
```

```python
from sklearn.decomposition import PCA
pca = PCA(n_components=50)
pca.fit(fruits_2d)

print(pca.components_.shape)
#(50,10000)
```
PCA class

n_components=50 : 첫번째 차원이 50이다. 

    #(50,10000)

    이는 50개의 주성분을 찾은 거다.

    두번째 차원은 항상 원본 데이터의 특성 개수와 같은 10,000입니다.

    이를 통해 가능한 것
    
    1. 데이터 이미지화
```python
draw_fruits(pca.components_.reshape(-1,100,100))
```
위의 코드로 100x100 사이즈인 50개의 이미지를 출력한다.

**투영**

이렇게 주성분을 찾았으니, 원본 데이터를 주성분에 투영하여 특성의 개수를 10,000개에서 50개로 줄일 수 있다. 

이때의 함수는 transform() 메서드를 이용한다.

```python
print(fruits_2d.shape)
# (300,10000)
fruits_pca = pca.transform(fruits_2d)
print(fruits_pca.shape)
# (300,50)
```

```python

```